{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8318545",
   "metadata": {},
   "source": [
    "<div style='width=100%; display:flex;flex-direction:row'><img  src=https://universidadeuropea.com/resources/media/images/universidad-europea-logo_poc9mEM.original.png width=100  style='  margin-left: auto;margin-right: auto; width: 25%; height:25%;'><img  src=https://i.ibb.co/1068C7j/EATEASER.jpg width=100 style='  margin-left: auto;margin-right: auto; width: 10%;height:25%;'></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ee9dce",
   "metadata": {},
   "source": [
    "<div style='margin:auto;text-align: center;font-family: \"Times New Roman\", Times, serif; font-weight: bold;'>PROYECTO COMUTACIONAL<br><br>EATEASER - VOZ A TEXTO</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c329ef59",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex;flex-direction:row'>\n",
    "    <div style='width:50%;margin-right:5cm;'>\n",
    "        <p style='font-family: \"Times New Roman\", Times, serif; font-weight: bold;'>ESTUDIANTES</p>\n",
    "<ul style='font-family: \"Times New Roman\", Times, serif;'>\n",
    "    <li>Adilem Dobras 21911633</li><li>Roberto Echevarria 21823680</li><li>Carlos Gonzales 22067726</li><li>Juan Carlos Rondeau 21816176</li></ul> </div>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3dfd23",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size: 19px;color:#6DA0FF;font-family:Georgia, Times, 'Times New Roman', serif;letter-spacing: 3px;font-weight: normal\">1. Importamos las librerias</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5e13fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pitu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pitu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\pitu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping stemmers\\rslp.zip.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import pathlib\n",
    "import sys\n",
    "import logging\n",
    "import json\n",
    "import numpy\n",
    "\n",
    "try:\n",
    "    from pytube import YouTube\n",
    "    from pytube import Playlist\n",
    "except ModuleNotFoundError:\n",
    "    !pip install pytube\n",
    "    from pytube import YouTube\n",
    "    from pytube import Playlist\n",
    "try:\n",
    "    import speech_recognition as sr\n",
    "except ModuleNotFoundError:\n",
    "    !pip install SpeechRecognition\n",
    "    import speech_recognition as sr\n",
    "try:\n",
    "    from pydub import AudioSegment\n",
    "    from pydub.silence import split_on_silence\n",
    "except:\n",
    "    !pip install pydub\n",
    "    from pydub import AudioSegment\n",
    "    from pydub.silence import split_on_silence\n",
    "try:\n",
    "    import moviepy.editor as mp\n",
    "except:\n",
    "    !pip install moviepy\n",
    "    import moviepy.editor as mp\n",
    "try:\n",
    "    from bs4 import BeautifulSoup\n",
    "except:\n",
    "    !pip install beautifulsoup4\n",
    "    from bs4 import BeautifulSoup\n",
    "try:\n",
    "    from nltk.stem import PorterStemmer\n",
    "    from nltk.tokenize import word_tokenize\n",
    "except:\n",
    "    !pip install nltk\n",
    "    from nltk.stem import PorterStemmer\n",
    "    from nltk.tokenize import word_tokenize\n",
    "try:\n",
    "    import pyrebase\n",
    "except:\n",
    "    !pip install pyrebase4\n",
    "    import pyrebase\n",
    "try:   \n",
    "    import nltk\n",
    "    #nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem.rslp import RSLPStemmer\n",
    "    nltk.download('rslp')\n",
    "except:\n",
    "    !pip install nltk\n",
    "    import nltk\n",
    "    #nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem.rslp import RSLPStemmer\n",
    "    nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bce916",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size: 19px;color:#6DA0FF;font-family:Georgia, Times, 'Times New Roman', serif;letter-spacing: 3px;font-weight: normal\">2. Inicio del programa</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f5340a",
   "metadata": {},
   "source": [
    "<h3  style='font-family: \"Times New Roman\", Times, serif; font-weight: bold;text-align:center;font-size:14px'>CLASE CONTROLADORVIDEO</h3><p style='font-family: \"Times New Roman\", Times, serif; font-size:14px'>En esta clase se realizará los ajustes para manejar el video recibido y manipularlo.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bb88615",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ControladorVideo:\n",
    "    def __init__(self,enlace): \n",
    "        fb=Firebase('recetastextos/')\n",
    "        self._idvideo = fb.reenumerar()\n",
    "        self.enlacevideo=enlace\n",
    "        self.yt=YouTube(self.enlacevideo)\n",
    "        self.nombrevideo=''\n",
    "        self.titulovideo=self.yt.title\n",
    "        self.autorvideo=self.yt.author\n",
    "        self.fechavideo=self.yt.publish_date\n",
    "        self.duracionvideo=self.yt.length\n",
    "        self.rec=RecursosAdicionales()\n",
    "    \"\"\"|DESCARGAR VIDEO URL: descarga el video de youtube\n",
    "       |return: devuelve una ruta absoluta\"\"\"\n",
    "    def descargarVideoURL(self):\n",
    "        recetasVideos = 'recetasvideos/'\n",
    "        #aqui creo un nuevo id para el nuevo video\n",
    "        self._idvideo= self._idvideo+1\n",
    "        #esta sera el archivo del video y su nuevo nombre\n",
    "        nombre='receta'+str(self._idvideo)\n",
    "        #le pedimos al pytube que solo nos descargue el audio y lo descargamos\n",
    "        t=self.yt.streams.filter(file_extension='mp4').first().download(output_path=recetasVideos,filename=nombre+'.mp4')\n",
    "        #devolvemos el nombre\n",
    "        return nombre\n",
    "    \"\"\"|PARSEO VIDEO: pasa el video de .mp4 a .wav\n",
    "       |nombre: es un string que se colocara el nombre del video\n",
    "       |return: devuelve el nuevo nombre del audio en .wav\"\"\"\n",
    "    def parseoVideo(self,nombre):\n",
    "        recetasVideos = 'recetasvideos/'\n",
    "        #tomamos el video en mp4 \n",
    "        track = mp.VideoFileClip(recetasVideos+nombre+'.mp4')\n",
    "        #cambiamos el video a .wav\n",
    "        nombre_wav=\"{}.wav\".format(nombre)\n",
    "        track.audio.write_audiofile(recetasVideos+nombre_wav)\n",
    "        track.close()\n",
    "        return nombre\n",
    "    \"\"\"|SPEECH TEXT:Transforma el audio a texto\n",
    "       |nombre: es un string que se colocara el nombre del video\n",
    "       |return: devuelve un string con el texto devuelto\"\"\"\n",
    "    def speech_text(self,nombre):\n",
    "        recetasVideos = 'recetasvideos/'\n",
    "        #instanciamos el recognizer\n",
    "        r = sr.Recognizer()\n",
    "        audio = sr.AudioFile(recetasVideos+nombre)\n",
    "        with audio as source:\n",
    "            audio_file = r.record(source)\n",
    "        #transcribimos el audio a texto\n",
    "        result = r.recognize_google(audio_file, language = 'es-ES')\n",
    "        return result\n",
    "    def data_json(self):\n",
    "        return {\"id\":self._idvideo, \"nombre\":self.titulovideo, \"autor\": self.autorvideo, \"fecha\":str(self.fechavideo),\"enlace\":str(self.enlacevideo)}\n",
    "    def indexar_datos(self):\n",
    "        return self.rec.indexar_datos(\"recetastextos/indice.json\",{\"id\":self._idvideo+1, \"nombre\":self.titulovideo, \"autor\": self.autorvideo, \"fecha\":str(self.fechavideo),\"enlace\":str(self.enlacevideo)})\n",
    "    \"\"\"|REPETIDO:Nos dice si el video ya se encuentra en nuestra bd\n",
    "       |fileName: nombre del json\n",
    "       |key: llave en donde queremos encontrar lo que buscamos\n",
    "       |buscar: elemento que estamos buscando\"\"\"\n",
    "    def repetido(self):\n",
    "        return self.rec.buscar_json('recetastextos/indice.json','nombre',self.titulovideo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b297ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3  style='font-family: \"Times New Roman\", Times, serif; font-weight: bold;text-align:center;font-size:14px'>CLASE DEPURADOR</h3><p style='font-family: \"Times New Roman\", Times, serif; font-size:14px'>En esta clase se realizará el proceso de extraccion, transformacion y carga de nuestro programa EATEASER.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d0598a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#si el video es mayor de 3 minutos no funciona\n",
    "#si el video es en ingles no funciona\n",
    "class Depurador:\n",
    "    def __init__(self): \n",
    "        self.rec=RecursosAdicionales()\n",
    "    \"\"\"|VIDEO: proceso etl donde extraemos al informacion del video \n",
    "       |enlace: es un string que se colocara el enlace del video\"\"\"\n",
    "    def video(self,enlace):\n",
    "        try:\n",
    "            #instanciamos el controlador de videos\n",
    "            cv=ControladorVideo(enlace)\n",
    "            fb=Firebase('recetastextos/')\n",
    "            \n",
    "            #paso 1: verificamos si existe en la database\n",
    "            if fb.validar_database(cv.titulovideo)==False:\n",
    "                #paso 2: guardamos en database datos principales\n",
    "                \n",
    "                #paso 3: descargamos el video\n",
    "                cv.nombrevideo=cv.descargarVideoURL()\n",
    "                print(\"id: \"+str(cv._idvideo))\n",
    "                fb.guardar_database(cv.data_json(),cv._idvideo)\n",
    "                #paso 4: pasamos el video a .wav\n",
    "                nombre=cv.parseoVideo(cv.nombrevideo)\n",
    "                #paso 5: evaluamos los silencios \n",
    "                try:                \n",
    "                    num_segm=self.rec.segcionarXsilencios(nombre)\n",
    "                    result=\"\"\n",
    "                    for i in range(num_segm):\n",
    "                        try:\n",
    "                            result=result+str(cv.speech_text(\"../temp_audios/{}_extracto{}.wav\".format(nombre,i+1)))\n",
    "                            result=result+\" \"\n",
    "                        except BaseException:\n",
    "                            logging.exception(\"An exception was thrown!\")\n",
    "                            audio1=AudioSegment.from_wav(\"temp_audios/{}_extracto{}.wav\".format(nombre,i+1))\n",
    "                            duracion=audio1.duration_seconds\n",
    "                            if duracion<=5:\n",
    "                                print(\"El extracto {} es un silencio\".format(i+1))\n",
    "                            elif duracion<=180:\n",
    "                                print(\"El extracto {} es música o ruido\".format(i+1))\n",
    "                            else:\n",
    "                                print(\"Error importante en el extracto {}\".format(i+1))\n",
    "                    #paso 6: borramos los chunks temporales de audio\n",
    "                    self.rec.eliminacion_audio(\"temp_audios\",\"wav\")\n",
    "                    try:\n",
    "                        quitarEmojis = dict.fromkeys(range(0x10000, sys.maxunicode + 1), 'NULL')\n",
    "                        tituloSinEmojis=cv.titulovideo.translate(quitarEmojis)\n",
    "                        autorSinEmojis=cv.autorvideo.translate(quitarEmojis)\n",
    "                        #paso 7: escribimos el texto recibido en un txt->se guarda en local\n",
    "                        resultado=self.rec.escritura(cv.nombrevideo,\"Titulo:\"+tituloSinEmojis+\"\\n\"+\"Autor:\"+autorSinEmojis+\"\\n\"+\"Fecha Publicacion:\"+str(cv.fechavideo)+\"\\n\"+\"Enlace: \"+str(cv.enlacevideo)+\"\\n\"+\"Entradilla:\"+result)\n",
    "                        #paso 8: guardamos el texto en una base de datos\n",
    "                        fb.guardar_firebase(cv.nombrevideo+'.txt')\n",
    "                        #paso 9: eliminamos los mp4\n",
    "                        self.rec.eliminacion_audio(\"recetasvideos\",\"mp4\")\n",
    "                    except BaseException:\n",
    "                        logging.exception(\"An exception was thrown!\")\n",
    "                        print(\"No se ha podido eliminar los caracteres corruptos el video: \"+ cv.nombrevideo + \" - \"+ cv.titulovideo)\n",
    "                        self.rec.eliminacion_audio(\"recetasvideos\",\"mp4\")\n",
    "                        return None   \n",
    "                except BaseException:\n",
    "                    logging.exception(\"An exception was thrown!\")\n",
    "                    print(\"No se ha podido transcribir el video: \"+ cv.nombrevideo + \" - \"+ cv.titulovideo+\" - \"+cv.enlacevideo)\n",
    "                    self.rec.eliminacion_audio(\"recetasvideos\",\"mp4\")\n",
    "                    self.rec.eliminacion_audio(\"temp_audios\",\"wav\")\n",
    "                    return None\n",
    "            else:\n",
    "                print('Este video se encuentra en la base de datos.')\n",
    "                resultado=\"\"\n",
    "            return resultado\n",
    "        except BaseException:\n",
    "            logging.exception(\"An exception was thrown!\")\n",
    "            print(\"No se ha podido descargar el video: \"+ cv.nombrevideo + \" - \"+ cv.titulovideo)\n",
    "            return None\n",
    "    def lista(self, enlace):\n",
    "        playlist_urls = Playlist(enlace)\n",
    "        for url in playlist_urls:\n",
    "            self.video(url)\n",
    "    def transformacion(self):\n",
    "        print()\n",
    "    def carga(self):\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c910592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aqui iran lecturas-escrituras-guardar-eliminar cosas en bases de datos\n",
    "class RecursosAdicionales:\n",
    "    \"\"\"|ESCRITURA: escribe textos txt\n",
    "       |nombre: nombre del \n",
    "       |return: devuelve el audio en texto\"\"\"    \n",
    "    def escritura(self,nombre,texto):\n",
    "        recetasTextos = './recetastextos/'\n",
    "        if not(os.path.exists(recetasTextos)):\n",
    "            os.mkdir(recetasTextos)\n",
    "        f = open(recetasTextos+nombre+'.txt', 'w')\n",
    "        f.write(texto)\n",
    "        f = open(recetasTextos+nombre+'.txt', \"r\")\n",
    "        print(f.read())\n",
    "        f.close()\n",
    "        \n",
    "    def lectura_json(self,fileName):\n",
    "        if self.documento_vacio(fileName):\n",
    "            with open(fileName, \"r\") as file:\n",
    "                    archivo=json.load(file)\n",
    "        else: \n",
    "            archivo=[]\n",
    "            print('El documento se encuentra vacio.')\n",
    "        return archivo\n",
    "    \n",
    "    def escritura_json(self,fileName,data):\n",
    "        with open(fileName, \"w\") as file:\n",
    "                json.dump(data, file)\n",
    "                file.close()\n",
    "    def buscar_json(self,fileName,key,buscar):\n",
    "        encontrado=False\n",
    "        if self.documento_vacio(fileName):\n",
    "            archivo_json=self.lectura_json(fileName)\n",
    "            for item in archivo_json:\n",
    "                if buscar in item[key]:\n",
    "                    print('encontrado')\n",
    "                    encontrado=True\n",
    "                    #no me gusta usar esto pero no tengo idea de como usar un while con json\n",
    "                    break\n",
    "        return encontrado\n",
    "    def documento_vacio(self,fileName):\n",
    "        return os.stat(fileName).st_size != 0\n",
    "    def indexar_datos(self,fileName,adicion):\n",
    "        if not(os.path.exists(fileName)):\n",
    "            os.mkdir(fileName)\n",
    "        data=[]\n",
    "        data=self.lectura_json(fileName)\n",
    "        data.append(adicion)\n",
    "        self.escritura_json(fileName,data)\n",
    "        \n",
    "    def eliminacion_audio(self,path,tipo):\n",
    "        url = './'+path+'/'\n",
    "        py_files = glob.glob(url+'*.'+tipo)\n",
    "        for py_file in py_files:\n",
    "            try:\n",
    "                os.remove(py_file)\n",
    "            except OSError as e:\n",
    "                print(f\"Error:{ e.strerror}\")\n",
    "    \n",
    "    def segcionarXsilencios(self,audio):\n",
    "        audio1=AudioSegment.from_wav(\"./recetasvideos/\"+audio+\".wav\")\n",
    "        var_min=1900\n",
    "        salir=False\n",
    "        while salir==False:\n",
    "            samples = audio1.get_array_of_samples()\n",
    "            segundo=88521\n",
    "            index=[]\n",
    "            for i in range(0,len(samples),int(segundo/5)):\n",
    "                dataSeg = samples[i:int(segundo/5)+i]\n",
    "                media=numpy.mean(dataSeg)\n",
    "                var=numpy.var(dataSeg)\n",
    "                if -10<=media<=10 and var<=var_min:\n",
    "                    index.append(i)\n",
    "\n",
    "            borrar=[]\n",
    "            guardado=0\n",
    "            for i in range(len(index)-1):\n",
    "                if index[i+1]<=index[i]+(20*segundo):\n",
    "                    if i==0:\n",
    "                        tiempo=(index[i])/segundo\n",
    "                    else:\n",
    "                        tiempo=(index[i+1]-guardado)/segundo\n",
    "                    if tiempo<=120:\n",
    "                        borrar.append(i)\n",
    "                    else:\n",
    "                        guardado=index[i]\n",
    "                else:\n",
    "                    guardado=index[i]\n",
    "\n",
    "            final=numpy.delete(index, borrar, axis=0) \n",
    "            extractos=[]\n",
    "            if len(final)==0:\n",
    "                var_min=var_min*10\n",
    "                salir=False\n",
    "            else:\n",
    "                for i in range(len(final)):\n",
    "                    if i==0:\n",
    "                        extractos.append(samples[:final[i]])\n",
    "                    else:\n",
    "                        extractos.append(samples[final[i-1]:final[i]])\n",
    "                extractos.append(samples[final[i]:])\n",
    "                salir=True\n",
    "\n",
    "        for i in range(len(extractos)):\n",
    "            nombre=\"\"\n",
    "            new_sound = audio1._spawn(extractos[i])\n",
    "            nombre=\"temp_audios/{}_extracto{}.wav\".format(audio,i+1)\n",
    "            new_sound.export(nombre,format=\"wav\")\n",
    "        #print(len(extractos))\n",
    "        return len(extractos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "131f35f6-ac5b-4c99-88a3-e47d738b6a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Firebase:\n",
    "    def __init__(self,ubicacion):\n",
    "        self.ubi=ubicacion\n",
    "        \n",
    "        self.config={\"apiKey\": \"AIzaSyDDg9WOlFJxnEJoxomYtsnkJfsI4TgoL_E\",\"authDomain\": \"eateaser-741d4.firebaseapp.com\",\"databaseURL\" : \"https://eateaser-741d4-default-rtdb.firebaseio.com/\",\"projectId\": \"eateaser-741d4\",\"storageBucket\": \"eateaser-741d4.appspot.com\",\"messagingSenderId\": \"706351391410\",\"appId\": \"1:706351391410:web:6abc2cabd6bf83843b5fab\",\"measurementId\": \"G-YZZCBRHNBT\"};\n",
    "        self.firebase=self.conexion_firebase()\n",
    "        self.database=self.firebase.database()\n",
    "    def conexion_firebase(self):\n",
    "        return pyrebase.initialize_app(self.config)\n",
    "    def guardar_firebase(self,nom):\n",
    "        storage=self.firebase.storage()\n",
    "        storage.child(self.ubi+nom).put(self.ubi+nom)\n",
    "    def eliminar_firebase(self,nom):\n",
    "        self.firebase.storage().delete(self.ubi+nom)\n",
    "    def guardar_database(self,data,_id):\n",
    "        self.database.child('Recetas').child(_id).set(data)\n",
    "    def validar_database(self,data):\n",
    "        validar=self.database.get()\n",
    "        encontrado=False\n",
    "        for a in validar.each():\n",
    "            if  data in str(a.val()):\n",
    "                encontrado=True\n",
    "                #no me gusta usar esto pero no tengo idea de como usar un while con json\n",
    "                break\n",
    "        return encontrado\n",
    "    def reenumerar(self):\n",
    "        recetas=self.database.child(\"Recetas\").get()\n",
    "        id=0\n",
    "        for item in recetas.each():\n",
    "            id=item.key()\n",
    "        return int(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e747077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebScrap:\n",
    "    def __init__(self): \n",
    "        self.headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "    def request(self, url):\n",
    "        request1 = requests.get(url, headers=self.headers)\n",
    "        html = request1.content\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        return soup\n",
    "    def verificar_alimento(self,alimento):\n",
    "        soup = self.request( 'https://www.themealdb.com/api/json/v1/1/search.php?s='+alimento)\n",
    "        print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f517c7a4",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size: 19px;color:#6DA0FF;font-family:Georgia, Times, 'Times New Roman', serif;letter-spacing: 3px;font-weight: normal\">3. Main</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f92c5289",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (1792459593.py, line 49)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [7]\u001b[1;36m\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "#y si tambien vemos si le permitimos al usuario que meta videos?\n",
    "dep=Depurador()\n",
    "if __name__ == '__main__':\n",
    "    #dep.video('https://www.youtube.com/watch?v=6PzQY1E2s2g&list=PLxHmjpcgU5ArC2rY5cpoIcZoVKB_0UHfR&ab_channel=PlatosF%C3%A1cilesconTamara')\n",
    "    #dep.video('https://www.youtube.com/watch?v=PsqR5M8rdjA&list=LL&index=9&t=4s')\n",
    "    #dep.video('https://www.youtube.com/watch?v=xfYcM_jHgPY')\n",
    "    #dep.video('https://www.youtube.com/watch?v=wiCfqc5W-yo')\n",
    "    #error_nuevo#dep.video('https://www.youtube.com/watch?v=3DnPkf9rP_0')\n",
    "    #error_nuevo#dep.video('https://www.youtube.com/watch?v=xVsgKMZFCZY')\n",
    "    #dep.video('https://www.youtube.com/watch?v=rpCe0RPMY94')\n",
    "    #dep.video('https://www.youtube.com/watch?v=rv4gLMa-FYk')\n",
    "    #dep.video('https://www.youtube.com/watch?v=VS8zYxBj4r8')\n",
    "    #dep.video('https://www.youtube.com/watch?v=o99JXrEkZoo')\n",
    "    #dep.video('https://www.youtube.com/watch?v=lKkg5L23b3M')\n",
    "    #dep.video('https://www.youtube.com/watch?v=PsqR5M8rdjA&t=14s')\n",
    "    #dep.video('https://www.youtube.com/watch?v=IvZaAL6qYe0&t=29s')\n",
    "    #dep.video('https://www.youtube.com/watch?v=SIMQBuuyE9M')\n",
    "    #dep.video('https://www.youtube.com/watch?v=_YoZfg7R8Hk')\n",
    "    #dep.video('https://www.youtube.com/watch?v=Zv7KdlOBk7Y')\n",
    "    #dep.video('https://www.youtube.com/watch?v=mFcN4btaZyI&t=2s')\n",
    "    #dep.video('https://www.youtube.com/watch?v=sRmmQBBln9Q')\n",
    "    #dep.video('https://www.youtube.com/watch?v=-QoTJJJfeEE')\n",
    "    #dep.video('https://www.youtube.com/watch?v=JRY5obPKPzo&list=PLxHmjpcgU5ArC2rY5cpoIcZoVKB_0UHfR&index=5&ab_channel=PlatosF%C3%A1cilesconTamara')\n",
    "    #dep.video('https://www.youtube.com/watch?v=stFmx7OCy1k&ab_channel=RecetasdeEsbieta')\n",
    "    #error_videomuylargo#dep.video(\"https://www.youtube.com/watch?v=qqTqePGIjhc\")\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLQwfLPYiFlOsS9x6zgeZmFRLqDx3poZvw\")\n",
    "    #dep.lista(\"https://www.youtube.com/playlist?list=PLIsSIvqffHZvM2v1QS5Zi0MUL258EKLPq\")\n",
    "    #dep.video('https://www.youtube.com/watch?v=rv4gLMa-FYk')\n",
    "    \n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLf2b-1EmxBEcmcj5GPFfFMbvegVKFOIYR\")\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PL2rWPa7BVMtzadghDZ7cHbkXuJ735RVnZ\")\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLiIutYe2uQJrwuRzF0_8tf_a651emeOiO\")\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLEOkiu1MfX7FsiTlZfaHZtMfo1EZD96tq\")\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PL8Vs-hI7gkl0yY6T0qbWSsw_Zv9d2cqnu\")#arroces\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PL8Id0yl_4Lo-AtOvrizH3OA6yOK0HLRPw\")#mariscos\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLxHmjpcgU5Apmx0uz4mfhWZmMFrIm-1a8\")#pasta **\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLxHmjpcgU5AqiG1XoX00meJj9rnNIp9qT\")#carnes\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLgDn1_a8qclShfo0yvUUPrX673yC3v8LR\")#pescados y algun marisco\n",
    "    #No acabada # dep.lista(\"https://youtube.com/playlist?list=PLge9wrsFXyuYHweFYpDMnHp95WYe6Prfn\")#verduras\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PL1DDoU1JPaGI0ZVkGbXPhUq2ttCVPBKc5\")#arroces\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PL75JfQSBdGa9ez55vz1evAkKtI_e8SzCh\")\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PL75JfQSBdGa9RP3HprHJHyLMmM2hC9uu7\")#marisco\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLNvWgJIx6X41jbPxHH0h6I_JJimIKzlVF\")#pasta\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLcPdHx9MSg_DAHTy258b0F1vdZE7nRHYX\")#pescado\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLWwMSMcUrXKFkBuQfR0uNB7E8TL7dnmfY\")#platosMenores\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLdLEn2GksKhaCS9QmsKaHcC4Yr6jCKHf_\")#verduras\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLoNzD53SxXZC84LG74DVYvqYCSwMaVIKn\")#platosMenores\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLUxqTjTdTvkN2JpDMcTKcMxEGZqmJ14Xu\")#platosMenores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1cfa42e1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0./recetastextos/Carpeta Arroz/-----------------\n",
      "['receta108.txt', 'receta125.txt', 'receta133.txt', 'receta134.txt', 'receta139.txt', 'receta160.txt', 'receta163.txt', 'receta165.txt', 'receta171.txt', 'receta172.txt', 'receta173.txt', 'receta174.txt', 'receta175.txt', 'receta177.txt', 'receta200.txt', 'receta358.txt', 'receta359.txt', 'receta360.txt', 'receta363.txt', 'receta364.txt', 'receta365.txt', 'receta366.txt', 'receta367.txt', 'receta368.txt', 'receta374.txt', 'receta376.txt', 'receta379.txt', 'receta386.txt', 'receta388.txt', 'receta389.txt', 'receta390.txt', 'receta391.txt', 'receta392.txt', 'receta393.txt', 'receta394.txt', 'receta395.txt', 'receta396.txt', 'receta397.txt', 'receta398.txt', 'receta400.txt', 'receta401.txt', 'receta402.txt', 'receta405.txt', 'receta406.txt', 'receta407.txt', 'receta410.txt', 'receta411.txt', 'receta412.txt', 'receta416.txt', 'receta417.txt', 'receta422.txt', 'receta429.txt', 'receta84.txt', 'receta90.txt']\n",
      "1./recetastextos/Carpeta Bebidas/-----------------\n",
      "['noBorrar.txt', 'receta623.txt', 'receta633.txt', 'receta634.txt', 'receta635.txt', 'receta636.txt', 'receta637.txt', 'receta638.txt', 'receta639.txt', 'receta640.txt', 'receta641.txt', 'receta642.txt', 'receta643.txt', 'receta644.txt', 'receta645.txt', 'receta646.txt', 'receta648.txt', 'receta649.txt', 'receta651.txt', 'receta652.txt', 'receta653.txt', 'receta654.txt', 'receta655.txt', 'receta656.txt', 'receta657.txt', 'receta658.txt', 'receta659.txt', 'receta660.txt', 'receta661.txt', 'receta662.txt', 'receta663.txt', 'receta664.txt', 'receta665.txt', 'receta666.txt', 'receta668.txt', 'receta669.txt', 'receta670.txt', 'receta671.txt', 'receta672.txt', 'receta674.txt', 'receta675.txt', 'receta676.txt', 'receta678.txt', 'receta679.txt', 'receta680.txt', 'receta681.txt', 'receta682.txt', 'receta683.txt', 'receta685.txt', 'receta686.txt', 'receta687.txt', 'receta688.txt', 'receta690.txt', 'receta692.txt', 'receta693.txt', 'receta694.txt', 'receta695.txt', 'receta696.txt', 'receta698.txt', 'receta700.txt', 'receta701.txt', 'receta702.txt', 'receta703.txt']\n",
      "2./recetastextos/Carpeta Carnes/-----------------\n",
      "['receta1.txt', 'receta114.txt', 'receta16.txt', 'receta209.txt', 'receta258.txt', 'receta259.txt', 'receta260.txt', 'receta261.txt', 'receta262.txt', 'receta263.txt', 'receta264.txt', 'receta266.txt', 'receta267.txt', 'receta268.txt', 'receta269.txt', 'receta270.txt', 'receta271.txt', 'receta272.txt', 'receta273.txt', 'receta274.txt', 'receta275.txt', 'receta276.txt', 'receta277.txt', 'receta278.txt', 'receta280.txt', 'receta281.txt', 'receta282.txt', 'receta283.txt', 'receta284.txt', 'receta285.txt', 'receta286.txt', 'receta287.txt', 'receta29.txt', 'receta3.txt', 'receta31.txt', 'receta32.txt', 'receta39.txt', 'receta42.txt', 'receta43.txt', 'receta48.txt', 'receta51.txt', 'receta58.txt', 'receta6.txt', 'receta63.txt', 'receta65.txt', 'receta71.txt', 'receta73.txt', 'receta77.txt', 'receta8.txt', 'receta83.txt', 'receta93.txt']\n",
      "3./recetastextos/Carpeta Marisco/-----------------\n",
      "['receta180.txt', 'receta184.txt', 'receta185.txt', 'receta195.txt', 'receta202.txt', 'receta203.txt', 'receta204.txt', 'receta205.txt', 'receta212.txt', 'receta213.txt', 'receta214.txt', 'receta216.txt', 'receta218.txt', 'receta219.txt', 'receta221.txt', 'receta224.txt', 'receta226.txt', 'receta26.txt', 'receta298.txt', 'receta306.txt', 'receta310.txt', 'receta319.txt', 'receta322.txt', 'receta330.txt', 'receta333.txt', 'receta334.txt', 'receta35.txt', 'receta41.txt', 'receta481.txt', 'receta486.txt', 'receta487.txt', 'receta491.txt', 'receta5.txt', 'receta501.txt', 'receta502.txt', 'receta505.txt', 'receta510.txt', 'receta515.txt', 'receta516.txt', 'receta517.txt', 'receta518.txt', 'receta520.txt', 'receta521.txt', 'receta522.txt', 'receta524.txt', 'receta525.txt', 'receta528.txt', 'receta532.txt', 'receta540.txt', 'receta541.txt', 'receta542.txt', 'receta544.txt', 'receta552.txt', 'receta602.txt', 'receta632.txt']\n",
      "4./recetastextos/Carpeta Pasta/-----------------\n",
      "['receta118.txt', 'receta120.txt', 'receta15.txt', 'receta228.txt', 'receta229.txt', 'receta230.txt', 'receta231.txt', 'receta232.txt', 'receta234.txt', 'receta235.txt', 'receta236.txt', 'receta237.txt', 'receta238.txt', 'receta239.txt', 'receta24.txt', 'receta240.txt', 'receta241.txt', 'receta242.txt', 'receta243.txt', 'receta244.txt', 'receta246.txt', 'receta247.txt', 'receta248.txt', 'receta249.txt', 'receta250.txt', 'receta252.txt', 'receta253.txt', 'receta254.txt', 'receta256.txt', 'receta257.txt', 'receta555.txt', 'receta556.txt', 'receta557.txt', 'receta558.txt', 'receta559.txt', 'receta56.txt', 'receta561.txt', 'receta563.txt', 'receta564.txt', 'receta566.txt', 'receta567.txt', 'receta568.txt', 'receta569.txt', 'receta570.txt', 'receta573.txt', 'receta574.txt', 'receta575.txt', 'receta576.txt', 'receta577.txt', 'receta578.txt', 'receta579.txt', 'receta580.txt', 'receta581.txt', 'receta582.txt', 'receta583.txt', 'receta584.txt', 'receta586.txt', 'receta587.txt', 'receta588.txt', 'receta589.txt', 'receta590.txt', 'receta591.txt', 'receta592.txt', 'receta95.txt']\n",
      "5./recetastextos/Carpeta Pescados/-----------------\n",
      "['receta11.txt', 'receta123.txt', 'receta181.txt', 'receta190.txt', 'receta194.txt', 'receta25.txt', 'receta297.txt', 'receta299.txt', 'receta301.txt', 'receta304.txt', 'receta323.txt', 'receta325.txt', 'receta332.txt', 'receta335.txt', 'receta336.txt', 'receta337.txt', 'receta338.txt', 'receta340.txt', 'receta480.txt', 'receta482.txt', 'receta484.txt', 'receta485.txt', 'receta488.txt', 'receta489.txt', 'receta490.txt', 'receta492.txt', 'receta493.txt', 'receta494.txt', 'receta495.txt', 'receta496.txt', 'receta497.txt', 'receta499.txt', 'receta500.txt', 'receta503.txt', 'receta504.txt', 'receta507.txt', 'receta508.txt', 'receta509.txt', 'receta513.txt', 'receta514.txt', 'receta519.txt', 'receta527.txt', 'receta530.txt', 'receta531.txt', 'receta537.txt', 'receta539.txt', 'receta596.txt', 'receta598.txt', 'receta601.txt', 'receta609.txt', 'receta611.txt', 'receta614.txt', 'receta617.txt', 'receta619.txt', 'receta620.txt', 'receta621.txt', 'receta622.txt', 'receta624.txt', 'receta625.txt', 'receta627.txt', 'receta629.txt', 'receta630.txt', 'receta7.txt', 'receta74.txt', 'receta81.txt', 'receta88.txt']\n",
      "6./recetastextos/Carpeta Platos Menores/-----------------\n",
      "['receta112.txt', 'receta14.txt', 'receta18.txt', 'receta2.txt', 'receta227.txt', 'receta27.txt', 'receta30.txt', 'receta38.txt', 'receta4.txt', 'receta47.txt', 'receta50.txt', 'receta53.txt', 'receta57.txt', 'receta60.txt', 'receta61.txt', 'receta69.txt', 'receta704.txt', 'receta705.txt', 'receta706.txt', 'receta711.txt', 'receta714.txt', 'receta716.txt', 'receta718.txt', 'receta72.txt', 'receta720.txt', 'receta721.txt', 'receta736.txt', 'receta737.txt', 'receta738.txt', 'receta739.txt', 'receta740.txt', 'receta741.txt', 'receta742.txt', 'receta743.txt', 'receta745.txt', 'receta746.txt', 'receta747.txt', 'receta748.txt', 'receta749.txt', 'receta75.txt', 'receta750.txt', 'receta751.txt', 'receta752.txt', 'receta754.txt', 'receta755.txt', 'receta757.txt', 'receta759.txt', 'receta760.txt', 'receta78.txt', 'receta87.txt', 'receta9.txt']\n",
      "7./recetastextos/Carpeta Verduras/-----------------\n",
      "['receta119.txt', 'receta13.txt', 'receta17.txt', 'receta296.txt', 'receta339.txt', 'receta342.txt', 'receta343.txt', 'receta346.txt', 'receta347.txt', 'receta348.txt', 'receta349.txt', 'receta350.txt', 'receta352.txt', 'receta353.txt', 'receta354.txt', 'receta355.txt', 'receta356.txt', 'receta357.txt', 'receta36.txt', 'receta431.txt', 'receta433.txt', 'receta434.txt', 'receta435.txt', 'receta436.txt', 'receta438.txt', 'receta439.txt', 'receta440.txt', 'receta442.txt', 'receta446.txt', 'receta447.txt', 'receta448.txt', 'receta451.txt', 'receta454.txt', 'receta455.txt', 'receta456.txt', 'receta457.txt', 'receta459.txt', 'receta460.txt', 'receta462.txt', 'receta608.txt', 'receta64.txt', 'receta723.txt', 'receta724.txt', 'receta725.txt', 'receta726.txt', 'receta729.txt', 'receta730.txt', 'receta731.txt', 'receta732.txt', 'receta733.txt', 'receta734.txt', 'receta92.txt', 'receta94.txt']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nprint(len(listaTextosCarpeta))\\n#for l in listaTextosCarpeta:\\n#    print('----------------------------------------------------------------------------')\\n#    print(l)\\n#    print('----------------------------------------------------------------------------')\\n#    print('----------------------------------------------------------------------------')\\n\\n\\nstemsArroz=p.tratamientoTextos(listaTextosCarpeta[0])\\nprint(stemsArroz)\\nstemsBebidas=p.tratamientoTextos(listaTextosCarpeta[1])\\nprint(stemsBebidas)\\nstemsCarne=p.tratamientoTextos(listaTextosCarpeta[2])\\nprint(stemsCarne)\\nstemsMarisco=p.tratamientoTextos(listaTextosCarpeta[3])\\nprint(stemsMarisco)\\nstemsPasta=p.tratamientoTextos(listaTextosCarpeta[4])\\nprint(stemsPasta)\\nstemsPescados=p.tratamientoTextos(listaTextosCarpeta[5])\\nprint(stemsPescados)\\nstemsPlatosMenores=p.tratamientoTextos(listaTextosCarpeta[6])\\nprint(stemsPlatosMenores)\\nstemsVerduras=p.tratamientoTextos(listaTextosCarpeta[7])\\nprint(stemsVerduras)\\n\\nprint('----------------------------')\\n\\nlistaTextosTesting=p.lecturaTesting()\\nprint(listaTextosTesting)\\nstemsTesting=p.tratamientoTextos(listaTextosTesting)\\nprint(stemsTesting)\\n\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ProcesarDocumentos:     \n",
    "    def lectura(self):\n",
    "        procDoc=ProcesarDocumentos()\n",
    "        rutaCarpetasPorCategoria = \"./recetastextos/\"\n",
    "        listaCarpetasFinal = []\n",
    "        #estos string nos servirán para guardar todos los textos de los txt por cada una de las carpetas\n",
    "        carpetaArroz = carpetaBebidas = carpetaCarnes = carpetaMarisco = carpetaPasta = carpetaPescados = carpetaPlatosMenores = carpetaVerduras = ''\n",
    "        #sacamos una lista de todas las carpetas\n",
    "        listaCarpetas = os.listdir(rutaCarpetasPorCategoria)\n",
    "        #print(listaCarpetas)\n",
    "        #print(len(listaCarpetas))\n",
    "        #recorremos todas las carpetas\n",
    "        i=0\n",
    "        for lc in listaCarpetas:\n",
    "            #cogemos el nombre de la carpeta y se lo concatenamos a la ruta anterior\n",
    "            rutaPorCarpeta = rutaCarpetasPorCategoria + lc + '/'\n",
    "            print(str(i)+rutaPorCarpeta+'-----------------')\n",
    "            if(i==0):\n",
    "                carpetaArroz = procDoc.resultadoStringCarpeta(rutaPorCarpeta)\n",
    "                #print(carpetaArroz)\n",
    "                listaCarpetasFinal.append(carpetaArroz)\n",
    "            if(i==1):\n",
    "                carpetaBebidas = procDoc.resultadoStringCarpeta(rutaPorCarpeta)\n",
    "                listaCarpetasFinal.append(carpetaBebidas)\n",
    "            if(i==2):\n",
    "                carpetaCarnes = procDoc.resultadoStringCarpeta(rutaPorCarpeta)\n",
    "                listaCarpetasFinal.append(carpetaCarnes)\n",
    "            if(i==3):\n",
    "                carpetaMarisco = procDoc.resultadoStringCarpeta(rutaPorCarpeta)\n",
    "                listaCarpetasFinal.append(carpetaMarisco)\n",
    "            if(i==4):\n",
    "                carpetaPasta = procDoc.resultadoStringCarpeta(rutaPorCarpeta)\n",
    "                listaCarpetasFinal.append(carpetaPasta)\n",
    "            if(i==5):\n",
    "                carpetaPescados = procDoc.resultadoStringCarpeta(rutaPorCarpeta)\n",
    "                listaCarpetasFinal.append(carpetaPescados)\n",
    "            if(i==6):\n",
    "                carpetaPlatosMenores = procDoc.resultadoStringCarpeta(rutaPorCarpeta)\n",
    "                listaCarpetasFinal.append(carpetaPlatosMenores)\n",
    "            if(i==7):\n",
    "                carpetaVerduras = procDoc.resultadoStringCarpeta(rutaPorCarpeta)\n",
    "                listaCarpetasFinal.append(carpetaVerduras)\n",
    "            i=i+1\n",
    "        return listaCarpetasFinal\n",
    "    def lecturaTesting(self):\n",
    "        procDoc=ProcesarDocumentos()\n",
    "        rutaCarpetaTesting = \"./recetastextostesting/Carpeta Testing/\"\n",
    "        carpetaTesting = procDoc.resultadoStringCarpeta(rutaCarpetaTesting)\n",
    "        return carpetaTesting\n",
    "    def resultadoStringCarpeta(self, rutaPorCarpeta):\n",
    "        strCarpeta=[]\n",
    "        #vemos el contenido de la carpeta en la que estamos iterando\n",
    "        listaTxt = os.listdir(rutaPorCarpeta)\n",
    "        print(listaTxt)\n",
    "        #recorremos todos los archivos de la carpeta\n",
    "        for lt in listaTxt:\n",
    "            #concatenamos la ruta de la carpeta con el nombre de los archivos que contiene esta\n",
    "            rutaTxt = rutaPorCarpeta + lt\n",
    "            #al ir iterando pasaremos por todos los archivos modificando la variable de la ruta para poder hacer un open con ella\n",
    "            with open(rutaTxt, 'r') as f: \n",
    "                #al hacer el open leemos lo que hay dentro del archivo con f.read(), y esto lo guardamos dentro de un string inicializado al inicio del todo\n",
    "                strCarpeta.append(f.read())\n",
    "        return strCarpeta\n",
    "    def leer_stopwords(self, path):\n",
    "        with open(path) as f:\n",
    "            # Lee las stopwords del archivo y las guarda en una lista\n",
    "            mis_stopwords = [line.strip() for line in f]\n",
    "        return mis_stopwords\n",
    "    def tratamientoTextos(self, info):\n",
    "        #Eliminamos posibles horas del titulo\n",
    "        textoSinSimbolos = re.sub(\"\\d+:\\d+:\\d+\", \"\" , info)\n",
    "        #Eliminamos posibles fechas\n",
    "        textoSinSimbolos = re.sub(\"\\d+-\\d+-\\d+\", \"\" , textoSinSimbolos)\n",
    "        #Eliminamos todos los fin de enlace\n",
    "        textoSinSimbolos = re.sub(\"v=.*\", \"\" , textoSinSimbolos)\n",
    "        #Eliminamos todos los simbolos del texto (,.;:?¿!!) etc\n",
    "        textoSinSimbolos = re.sub(\"[^0-9A-Za-z_]\", \" \" , textoSinSimbolos)\n",
    "        #Sacamos todos los tokens del texto y los metemos en una lista\n",
    "        textoTokenizado = nltk.tokenize.word_tokenize(textoSinSimbolos)\n",
    "        #una lista no tiene lower asique pasamos el lower con map a toda la lista\n",
    "        textoMinusculas = (map(lambda x: x.lower(), textoTokenizado))\n",
    "        #Le pasa un stopword de palabras en español a la lista de palabras que le llega\n",
    "        #stop_words_sp = set(stopwords.words('spanish'))\n",
    "        stop_words_sp = self.leer_stopwords(\"./rapidminer/stop_words_spanish.txt\")\n",
    "        pasarStopWords = [i for i in textoMinusculas if i not in stop_words_sp]\n",
    "        #Aplicamos la normalizacion mediante stemming\n",
    "        #SnowStem = nltk.SnowballStemmer(language = 'spanish')\n",
    "        # Crear un objeto SnowballStemmer para el idioma español\n",
    "        stemmer = RSLPStemmer()\n",
    "        listaStems = [stemmer.stem(word) for word in pasarStopWords]\n",
    "        return listaStems\n",
    "\n",
    "\n",
    "p=ProcesarDocumentos()\n",
    "listaTextosCarpeta=p.lectura()\n",
    "\"\"\"\n",
    "print(len(listaTextosCarpeta))\n",
    "#for l in listaTextosCarpeta:\n",
    "#    print('----------------------------------------------------------------------------')\n",
    "#    print(l)\n",
    "#    print('----------------------------------------------------------------------------')\n",
    "#    print('----------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "stemsArroz=p.tratamientoTextos(listaTextosCarpeta[0])\n",
    "print(stemsArroz)\n",
    "stemsBebidas=p.tratamientoTextos(listaTextosCarpeta[1])\n",
    "print(stemsBebidas)\n",
    "stemsCarne=p.tratamientoTextos(listaTextosCarpeta[2])\n",
    "print(stemsCarne)\n",
    "stemsMarisco=p.tratamientoTextos(listaTextosCarpeta[3])\n",
    "print(stemsMarisco)\n",
    "stemsPasta=p.tratamientoTextos(listaTextosCarpeta[4])\n",
    "print(stemsPasta)\n",
    "stemsPescados=p.tratamientoTextos(listaTextosCarpeta[5])\n",
    "print(stemsPescados)\n",
    "stemsPlatosMenores=p.tratamientoTextos(listaTextosCarpeta[6])\n",
    "print(stemsPlatosMenores)\n",
    "stemsVerduras=p.tratamientoTextos(listaTextosCarpeta[7])\n",
    "print(stemsVerduras)\n",
    "\n",
    "print('----------------------------')\n",
    "\n",
    "listaTextosTesting=p.lecturaTesting()\n",
    "print(listaTextosTesting)\n",
    "stemsTesting=p.tratamientoTextos(listaTextosTesting)\n",
    "print(stemsTesting)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9dec6bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Titulo:Arroz meloso de sepia con gambas y alcachofas | Receta de Cocina en Familia\\nAutor:Cocina en familia\\nFecha Publicacion:2022-06-09 00:00:00\\nEnlace: https://www.youtube.com/watch?v=9rcOvBJZm4U\\nEntradilla:receta que quiero compartir con todos vosotros hoy es un riquísimo arroz meloso de sepia con gambas y alcachofas y para ello tengo aquí los siguientes ingredientes una sepia hermosa que pesa 600 gramos 300 gramos de gambas 300 g de arroz 150 g de tomate natural rallado 50 g de cebolla partida 2 dientes de ajo perejil fresco un poco de pimentón dulce una obra de azafrán tres alcachofas cómo se ven tamaño mediana '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listaTextosCarpeta[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3316067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>receta</th>\n",
       "      <th>clasif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ensal, arroz, mediterr, nea, veran, cociner, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[arroz, mel, sep, gamb, alcachof, recet, cocin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[arroz, manit, cerd, set, recet, cocin, famil,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[paell, bacala, costr, aliol, recet, cocin, fa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[calder, alcachof, recet, cocin, famil, cocin,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>[calabac, n, m, s, delici, com, recet, calabac...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>[fr, cali, tu, decid, com, delic, repoll, rece...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>[sop, past, alem, past, elab, 1, minut, d, as,...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>[recet, crem, calabaz, companion, jord, cruz, ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>[patat, mediterrane, andaluc, videorecet, entr...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>457 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                receta clasif\n",
       "0    [ensal, arroz, mediterr, nea, veran, cociner, ...      0\n",
       "1    [arroz, mel, sep, gamb, alcachof, recet, cocin...      0\n",
       "2    [arroz, manit, cerd, set, recet, cocin, famil,...      0\n",
       "3    [paell, bacala, costr, aliol, recet, cocin, fa...      0\n",
       "4    [calder, alcachof, recet, cocin, famil, cocin,...      0\n",
       "..                                                 ...    ...\n",
       "452  [calabac, n, m, s, delici, com, recet, calabac...      7\n",
       "453  [fr, cali, tu, decid, com, delic, repoll, rece...      7\n",
       "454  [sop, past, alem, past, elab, 1, minut, d, as,...      7\n",
       "455  [recet, crem, calabaz, companion, jord, cruz, ...      7\n",
       "456  [patat, mediterrane, andaluc, videorecet, entr...      7\n",
       "\n",
       "[457 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df=pd.DataFrame()\n",
    "df['receta']=None\n",
    "df['clasif']=None\n",
    "\n",
    "for index,content in enumerate(listaTextosCarpeta):\n",
    "    for i in range(len(content)):\n",
    "        text=p.tratamientoTextos(listaTextosCarpeta[index][i])\n",
    "        df=df.append({'receta':text,'clasif':index},ignore_index=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "151319e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb6b4866",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 10000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2776350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_cv, Y_train, Y_cv = train_test_split(df[\"receta\"], df[\"clasif\"], test_size = 0.2, random_state=42)\n",
    "Y_train=list(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a146dc04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 6131)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "hola=[]\n",
    "for i,j in enumerate(X_train):\n",
    "    hola.append(\" \".join(j))\n",
    "hola[1]\n",
    "\n",
    "X_train = vectorizer.fit_transform(hola)\n",
    "X_train = X_train.toarray()\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "57366263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 6131)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hola=[]\n",
    "for i,j in enumerate(X_cv):\n",
    "    hola.append(\" \".join(j))\n",
    "hola[1]\n",
    "\n",
    "X_cv = vectorizer.transform(hola)\n",
    "X_cv = X_cv.toarray()\n",
    "print(X_cv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5324cbda",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b4bfe3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.782608695652174\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier() \n",
    "forest = forest.fit(X_train, Y_train)\n",
    "\n",
    "predictions = forest.predict(X_cv) \n",
    "Y_cv=list(Y_cv)\n",
    "print(\"Accuracy: \", accuracy_score(Y_cv, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2ad5000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "35d0626d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5760869565217391\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "vecinos = KNeighborsClassifier() \n",
    "vecinos = vecinos.fit(X_train, Y_train)\n",
    "\n",
    "predictions = vecinos.predict(X_cv) \n",
    "Y_cv=list(Y_cv)\n",
    "print(\"Accuracy: \", accuracy_score(Y_cv, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b98db68",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b2c7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    " Tratamiento de datos\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Gráficos\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Modelado\n",
    "# ==============================================================================\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "import multiprocessing\n",
    "\n",
    "# Configuración warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
